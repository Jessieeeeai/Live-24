import os
import json
import time
import re
import datetime
from langchain_openai import ChatOpenAI
from tavily import TavilyClient

# å†å²è®°å½•æ–‡ä»¶
HISTORY_FILE = "topic_history.json"

class CryptoBrain:
    def __init__(self, deepseek_key, tavily_key, topic_scope, persona_prompt, backup_topics, target_domains):
        self.backup_topics = backup_topics
        self.target_domains = target_domains # ç”¨æˆ·æŒ‡å®šçš„ä¿¡æºåˆ—è¡¨
        
        # 1. åˆå§‹åŒ–å¤§è„‘ (DeepSeek)
        if deepseek_key:
            self.llm = ChatOpenAI(
                model="deepseek-chat", 
                api_key=deepseek_key,
                base_url="https://api.deepseek.com",
                temperature=1.3, # æé«˜åˆ›é€ æ€§ï¼Œæ¨¡æ‹ŸçœŸäººèŠå¤©çš„å‘æ•£æ€§
                timeout=60  # å¢åŠ è¶…æ—¶æ—¶é—´
            )
        else:
            self.llm = None
            
        # 2. åˆå§‹åŒ–æœç´¢ (Tavily)
        self.tavily = TavilyClient(api_key=tavily_key) if tavily_key else None
        self.topic = topic_scope
        self.persona = persona_prompt
        
        # 3. å®šä¹‰æ·±åº¦åˆ†ææ¡†æ¶ SOP
        self.frameworks = {
            "5W1H": "çƒ­ç‚¹è§£è¯» (Who, What, Where, When, Why, How)",
            "PEST": "è¶‹åŠ¿åˆ†æ (æ”¿æ²» Political, ç»æµ Economic, ç¤¾ä¼š Social, æŠ€æœ¯ Technology)",
            "SWOT": "äº‰è®®äººç‰©/é¡¹ç›® (ä¼˜åŠ¿ Strengths, åŠ£åŠ¿ Weaknesses, æœºä¼š Opportunities, å¨èƒ Threats)",
            "MECE": "æ·±åº¦å¤ç›˜ (å®Œå…¨ç©·å°½ï¼Œç›¸äº’ç‹¬ç«‹)"
        }

    def _check_duplication(self, new_topic):
        """
        5å°æ—¶å»é‡æœºåˆ¶ï¼šé¿å…çŸ­æ—¶é—´å†…é‡å¤è®²åŒä¸€ä¸ªæ–°é—»
        """
        try:
            if not os.path.exists(HISTORY_FILE):
                # æ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ›å»ºåˆå§‹è®°å½•
                with open(HISTORY_FILE, "w") as f:
                    json.dump([{"topic": new_topic, "time": time.time()}], f)
                return False
            
            with open(HISTORY_FILE, "r") as f: 
                history = json.load(f)
            
            # 1. æ¸…ç†è¶…è¿‡5å°æ—¶çš„æ—§è®°å½•
            current_time = time.time()
            valid_history = [h for h in history if current_time - h['time'] < 5 * 3600]
            
            # 2. æŸ¥é‡ (ç®€å•å…³é”®è¯åŒ¹é… + ç›¸ä¼¼åº¦æ£€æµ‹)
            is_dup = False
            for h in valid_history:
                # æ–¹æ³•1ï¼šåŒ…å«å…³ç³»
                if h['topic'] in new_topic or new_topic in h['topic']:
                    is_dup = True
                    break
                # æ–¹æ³•2ï¼šæå–å…³é”®è¯å¯¹æ¯”
                old_words = set(re.findall(r'\w+', h['topic'].lower()))
                new_words = set(re.findall(r'\w+', new_topic.lower()))
                # å¦‚æœæœ‰è¶…è¿‡ 50% çš„å…³é”®è¯é‡å ï¼Œè§†ä¸ºé‡å¤
                if len(old_words & new_words) / max(len(new_words), 1) > 0.5:
                    is_dup = True
                    break
            
            # 3. å¦‚æœä¸é‡å¤ï¼Œæ›´æ–°æ–‡ä»¶
            if not is_dup:
                valid_history.append({"topic": new_topic, "time": current_time})
                with open(HISTORY_FILE, "w") as f: 
                    json.dump(valid_history, f, ensure_ascii=False, indent=2)
                print(f"âœ… æ–°è¯é¢˜å·²è®°å½•: {new_topic[:30]}...")
            else:
                print(f"âš ï¸ è¯é¢˜é‡å¤ï¼Œè·³è¿‡: {new_topic[:30]}...")
            
            return is_dup
        except Exception as e:
            print(f"âš ï¸ å»é‡æ£€æŸ¥å¤±è´¥: {e}")
            return False

    def _clean_text(self, text):
        """
        ğŸ”¥ å¼ºåŠ›å»åºŸè¯æ­£åˆ™æ¸…æ´—å™¨
        """
        if not text:
            return ""
        
        # 1. å»æ‰ (éŸ³æ•ˆ: xxx), [åŠ¨ä½œ], ã€èƒŒæ™¯éŸ³ã€‘, <æ ‡ç­¾>
        text = re.sub(r"[\(\[\ã€<].*?[\)\]\ã€‘>]", "", text)
        
        # 2. å»æ‰ Markdown æ ¼å¼ç¬¦å·
        text = text.replace("*", "").replace("#", "").replace("`", "")
        text = text.replace("_", "").replace("~", "")
        
        # 3. å»æ‰ AI ä¹ æƒ¯æ€§åºŸè¯ï¼ˆæ‰©å±•åˆ—è¡¨ï¼‰
        bad_phrases = [
            "å¥½çš„å¤§æ¼‚äº®", "æ²¡é—®é¢˜", "å¥½çš„", "ç»¼ä¸Šæ‰€è¿°", "æ€»ä¹‹", 
            "ä¸»æŒäºº", "Let's go", "å„ä½å¬ä¼—", "å¤§å®¶å¥½",
            "æ¥ä¸‹æ¥", "é‚£ä¹ˆ", "é¦–å…ˆ", "å…¶æ¬¡", "æœ€å",
            "å€¼å¾—æ³¨æ„çš„æ˜¯", "éœ€è¦æŒ‡å‡ºçš„æ˜¯", "æˆ‘ä»¬å¯ä»¥çœ‹åˆ°",
            "æ ¹æ®ä»¥ä¸Šåˆ†æ", "é€šè¿‡åˆ†æ", "å¯ä»¥å‘ç°",
            "éŸ³æ•ˆ", "èƒŒæ™¯éŸ³ä¹", "æŒå£°", "ç¬‘å£°"
        ]
        for phrase in bad_phrases:
            text = text.replace(phrase, "")
        
        # 4. å»é™¤ä¸é€‚åˆæœ—è¯»çš„æ ‡ç‚¹ç¬¦å·ï¼ˆä¿ç•™åŸºæœ¬æ ‡ç‚¹ï¼‰
        # ç§»é™¤ï¼šå¼•å·ã€æ‹¬å·ã€ä¹¦åå·ç­‰
        text = re.sub(r'["""''ã€Œã€ã€ã€ï¼ˆï¼‰\(\)\[\]ã€ã€‘ã€Šã€‹<>]', '', text)
        
        # 5. è§„èŒƒåŒ–æ ‡ç‚¹ï¼šå¤šä¸ªæ ‡ç‚¹åˆå¹¶ä¸ºä¸€ä¸ª
        text = re.sub(r'[ï¼Œ,]{2,}', 'ï¼Œ', text)
        text = re.sub(r'[ã€‚.]{2,}', 'ã€‚', text)
        text = re.sub(r'[ï¼!]{2,}', 'ï¼', text)
        text = re.sub(r'[ï¼Ÿ?]{2,}', 'ï¼Ÿ', text)
        
        # 6. å»é™¤å¤šä½™ç©ºè¡Œå’Œç©ºæ ¼
        lines = [line.strip() for line in text.split("\n") if line.strip()]
        text = "\n".join(lines)
        
        # 7. å»é™¤è¡Œé¦–çš„åºå·ï¼ˆ1. 2. ä¸€ã€äºŒã€ç­‰ï¼‰
        text = re.sub(r'^\s*[\dä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+[ã€\.\s]+', '', text, flags=re.MULTILINE)
        
        return text.strip()

    def fetch_news_and_analyze(self):
        """
        ä¸»æµç¨‹ï¼šæœç´¢æ–°é—» -> åˆ†æ -> ç”Ÿæˆæ–‡æ¡ˆ
        è¿”å›ï¼š(script, error, is_backup)
        """
        if not self.tavily: 
            return None, "ç¼ºå°‘ Tavily Key", False
        
        # ğŸŸ¢ è·å–ä»Šå¤©æ—¥æœŸï¼Œå¼ºåˆ¶æœæœ€æ–°
        today_str = datetime.datetime.now().strftime("%Y-%m-%d")
        print(f"ğŸ” æ­£åœ¨ä»æŒ‡å®šä¿¡æºæœç´¢ {today_str} çš„ {self.topic} æ–°é—»...")
        
        # å¤„ç†ç”¨æˆ·æŒ‡å®šçš„åŸŸå
        domain_list = [d.strip() for d in self.target_domains.split(",") if d.strip()]
        
        try:
            # ğŸ”¥ Tavily é«˜çº§æœç´¢é…ç½®
            response = self.tavily.search(
                query=f"breaking news {self.topic} crypto blockchain {today_str}",
                search_depth="advanced",
                include_domains=domain_list if domain_list else None, # åªæœæŒ‡å®šç½‘ç«™
                max_results=10,  # å¢åŠ æœç´¢ç»“æœæ•°é‡
                days=1  # å¼ºåˆ¶ 24 å°æ—¶å†…
            )
            results = response.get("results", [])
            print(f"ğŸ“° æœç´¢åˆ° {len(results)} æ¡ç»“æœ")
        except Exception as e:
            print(f"âŒ æœç´¢å¤±è´¥: {e}")
            return None, f"æœç´¢å¤±è´¥: {e}", False

        # ç­›é€‰æœªè®²è¿‡çš„æ–°é—»
        selected_news = None
        for item in results:
            title = item.get('title', '')
            if title and not self._check_duplication(title):
                selected_news = item
                break
        
        # æ²¡æ–°é—» -> å¯ç”¨ CMS å¤‡ç”¨åº“
        if not selected_news:
            print("âš ï¸ æ— æœ€æ–°é«˜ä»·å€¼æ–°é—»ï¼Œæˆ–éƒ½å·²è®²è¿‡ã€‚å¯ç”¨å¤‡ç”¨è¯é¢˜åº“...")
            import random
            if self.backup_topics:
                backup = random.choice(self.backup_topics)
            else:
                backup = "æ¯”ç‰¹å¸å»ä¸­å¿ƒåŒ–ç²¾ç¥ç§‘æ™®"
            
            print(f"ğŸ“š ä½¿ç”¨å¤‡ç”¨è¯é¢˜: {backup}")
            return backup, None, True  # True = æ˜¯å¤‡ç”¨å†…å®¹

        print(f"âœ… é€‰ä¸­å¤´æ¡: {selected_news['title']}")

        # æ„å»ºåˆ†ææ¡†æ¶æç¤ºè¯åˆ—è¡¨
        framework_str = "\n".join([f"- {k}: {v}" for k, v in self.frameworks.items()])
        
        # ğŸ”¥ æ ¸å¿ƒ Promptï¼šSOP + å»åºŸè¯ + å£è¯­åŒ–
        prompt = f"""
{self.persona}

ã€åŸå§‹æ–°é—»ã€‘
æ ‡é¢˜ï¼š{selected_news['title']}
å†…å®¹ï¼š{selected_news['content']}
æ¥æºï¼š{selected_news['url']}

ã€ä»»åŠ¡æŒ‡ä»¤ - è¯·ä¸¥æ ¼æ‰§è¡Œã€‘
1. **æ€ç»´é“¾åˆ†æ**ï¼šå…ˆåœ¨å†…å¿ƒæ€è€ƒï¼Œä»ä»¥ä¸‹æ¡†æ¶ä¸­é€‰ä¸€ä¸ªæœ€é€‚åˆçš„è¿›è¡Œæ¨æ¼”ï¼š
{framework_str}

2. **æ·±åº¦æ’°å†™**ï¼š
   - å°†åˆ†æç»“æœè½¬åŒ–ä¸ºä¸€ç¯‡ã€å£è¯­åŒ–ã€‘çš„æ’­å®¢æ–‡æ¡ˆã€‚
   - å¿…é¡»æœ‰çŠ€åˆ©è§‚ç‚¹ï¼Œä¸èƒ½åªæ˜¯å¤è¿°æ–°é—»ã€‚
   - å¥å­è¦çŸ­ï¼ŒèŠ‚å¥è¦å¿«ï¼ŒåƒçœŸäººåœ¨èŠå¤©ã€‚
   - é€‚åˆå¥³æ€§ä¸»æŒäººæ’­æŠ¥çš„è¯­æ°”å’Œç”¨è¯ã€‚

3. **æ ¼å¼æ¸…æ´— (è¿è€…æ­»æœº)**ï¼š
   - ä¸¥ç¦è¾“å‡º "æˆ‘é€‰æ‹©äº†xxæ¡†æ¶" æˆ– "å¥½çš„" ç­‰å…ƒè¯­è¨€ã€‚
   - ä¸¥ç¦åŒ…å« (éŸ³æ•ˆ)ã€ã€åŠ¨ä½œã€‘ã€[èƒŒæ™¯éŸ³] ç­‰å‰§æœ¬æ ‡è®°ã€‚
   - ä¸¥ç¦ä½¿ç”¨å¼•å·ã€æ‹¬å·ç­‰ä¸é€‚åˆæœ—è¯»çš„æ ‡ç‚¹ç¬¦å·ã€‚
   - ä¸¥ç¦ä½¿ç”¨"ç»¼ä¸Šæ‰€è¿°"ã€"æ€»ä¹‹"ã€"æ¥ä¸‹æ¥"ç­‰ä¹¦é¢è¯­ã€‚
   - åªä½¿ç”¨é€—å·ã€å¥å·ã€é—®å·ã€æ„Ÿå¹å·ä½œä¸ºæ ‡ç‚¹ã€‚
   - å­—æ•°æ§åˆ¶åœ¨ 500-700 å­—ä¹‹é—´ã€‚

4. **è¾“å‡ºè¦æ±‚**ï¼š
   - ç›´æ¥è¾“å‡ºæœ€ç»ˆçš„æ’­å®¢æ–‡æ¡ˆã€‚
   - è¯­æ°”è‡ªç„¶æµç•…ï¼Œåƒæ˜¯åœ¨å’Œæœ‹å‹èŠå¤©ã€‚
   - åŒ…å«æƒ…æ„Ÿå’ŒèŠ‚å¥å˜åŒ–ã€‚

ç°åœ¨å¼€å§‹åˆ›ä½œï¼š
"""
        
        try:
            # è°ƒç”¨ DeepSeek
            print("ğŸ§  DeepSeek æ­£åœ¨æ·±åº¦åˆ†æ...")
            raw_script = self.llm.invoke(prompt).content
            
            # æ¸…æ´—ç»“æœ
            print("ğŸ§¹ æ¸…æ´—æ–‡æ¡ˆ...")
            clean_script = self._clean_text(raw_script)
            
            # éªŒè¯è¾“å‡ºè´¨é‡
            if len(clean_script) < 100:
                print("âš ï¸ ç”Ÿæˆå†…å®¹è¿‡çŸ­ï¼Œå¯èƒ½å­˜åœ¨é—®é¢˜")
                return None, "ç”Ÿæˆå†…å®¹è´¨é‡ä¸ä½³", False
            
            print(f"âœ… æ–‡æ¡ˆç”Ÿæˆå®Œæˆï¼Œå…± {len(clean_script)} å­—")
            return clean_script, None, False
            
        except Exception as e:
            print(f"âŒ ç”Ÿæˆå¤±è´¥: {e}")
            return None, f"ç”Ÿæˆå¤±è´¥: {e}", False
