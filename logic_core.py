import os
import json
import time
import re
import datetime
from langchain_openai import ChatOpenAI
from tavily import TavilyClient

# å†å²è®°å½•æ–‡ä»¶
HISTORY_FILE = "topic_history.json"

class CryptoBrain:
    def __init__(self, deepseek_key, tavily_key, topic_scope, persona_prompt, backup_topics, target_domains):
        self.backup_topics = backup_topics
        self.target_domains = target_domains  # ç”¨æˆ·æŒ‡å®šçš„ä¿¡æºåˆ—è¡¨
        
        # 1. åˆå§‹åŒ–å¤§è„‘ (DeepSeek)
        if deepseek_key:
            self.llm = ChatOpenAI(
                model="deepseek-chat", 
                api_key=deepseek_key,
                base_url="https://api.deepseek.com",
                temperature=1.2,  # æé«˜åˆ›é€ æ€§
                timeout=120,  # å¢åŠ è¶…æ—¶æ—¶é—´ï¼Œæ”¯æŒæ·±åº¦åˆ†æ
                max_tokens=4000  # ğŸ”¥ æ˜ç¡®è®¾ç½®æœ€å¤§tokenæ•°ï¼Œç¡®ä¿é•¿å†…å®¹ç”Ÿæˆ
            )
        else:
            self.llm = None
            
        # 2. åˆå§‹åŒ–æœç´¢ (Tavily)
        self.tavily = TavilyClient(api_key=tavily_key) if tavily_key else None
        self.topic = topic_scope
        self.persona = persona_prompt
        
        # 3. ğŸ”¥ å®šä¹‰10ç§æ·±åº¦åˆ†ææ¡†æ¶ (å®Œæ•´ç‰ˆ)
        self.frameworks = {
            "5W1H": {
                "name": "çƒ­ç‚¹è§£è¯»æ¡†æ¶",
                "structure": "äº‹ä»¶æ¦‚è¿°â†’èƒŒæ™¯åˆ†æâ†’å…³é”®äººç‰©â†’æ—¶é—´è„‰ç»œâ†’æ·±å±‚åŸå› â†’å½±å“é¢„æµ‹",
                "é€‚ç”¨": ["çªå‘äº‹ä»¶", "æ–°é—»å¿«è®¯", "å®æ—¶åŠ¨æ€"]
            },
            "PEST": {
                "name": "è¶‹åŠ¿åˆ†ææ¡†æ¶",
                "structure": "æ”¿æ²»å› ç´ â†’ç»æµç¯å¢ƒâ†’ç¤¾ä¼šæ–‡åŒ–â†’æŠ€æœ¯å˜é©â†’ç»¼åˆå½±å“â†’è¶‹åŠ¿åˆ¤æ–­",
                "é€‚ç”¨": ["å¸‚åœºè¶‹åŠ¿", "å®è§‚ç¯å¢ƒ", "é•¿æœŸå˜åŒ–"]
            },
            "MECE": {
                "name": "å•†ä¸šäº‹ä»¶æ¡†æ¶",
                "structure": "é—®é¢˜æ‹†è§£â†’åˆ†ç±»å½’çº³â†’é€å±‚åˆ†æâ†’é€»è¾‘éªŒè¯â†’ç»“è®ºæ•´åˆ",
                "é€‚ç”¨": ["å•†ä¸šå†³ç­–", "æˆ˜ç•¥åˆ†æ", "å¤æ‚é—®é¢˜"]
            },
            "SWOT": {
                "name": "äººç‰©äº‰è®®æ¡†æ¶",
                "structure": "ä¼˜åŠ¿åˆ†æâ†’åŠ£åŠ¿å‰–æâ†’æœºä¼šè¯†åˆ«â†’å¨èƒè¯„ä¼°â†’æˆ˜ç•¥å»ºè®®",
                "é€‚ç”¨": ["äººç‰©è¯„ä»·", "é¡¹ç›®è¯„ä¼°", "ç«äº‰åˆ†æ"]
            },
            "åˆ©ç›Šç›¸å…³è€…": {
                "name": "æ”¿ç­–è§£è¯»æ¡†æ¶",
                "structure": "æ”¿åºœå±‚é¢â†’ä¼ä¸šè§’åº¦â†’æ°‘ä¼—è§†è§’â†’ä¸“å®¶è§‚ç‚¹â†’åª’ä½“ç«‹åœºâ†’ç»¼åˆå¹³è¡¡",
                "é€‚ç”¨": ["æ”¿ç­–å‘å¸ƒ", "ç›‘ç®¡å˜åŒ–", "å…¬å…±äº‹ä»¶"]
            },
            "æ³¢ç‰¹äº”åŠ›": {
                "name": "äº§ä¸šå˜åŒ–æ¡†æ¶",
                "structure": "ç«äº‰å¯¹æ‰‹â†’ä¾›åº”å•†â†’ä¹°æ–¹â†’æ›¿ä»£å“â†’æ½œåœ¨è¿›å…¥è€…â†’è¡Œä¸šå‰æ™¯",
                "é€‚ç”¨": ["è¡Œä¸šåˆ†æ", "ç«äº‰æ ¼å±€", "å¸‚åœºè¿›å…¥"]
            },
            "é‡‘å­—å¡”åŸç†": {
                "name": "ç¤¾ä¼šç°è±¡æ¡†æ¶",
                "structure": "æ ¸å¿ƒè§‚ç‚¹â†’æ”¯æ’‘è®ºæ®â†’å…·ä½“äº‹å®â†’é€»è¾‘æ¨ç†â†’ç»“è®ºå¼ºåŒ–",
                "é€‚ç”¨": ["è§‚ç‚¹è¡¨è¾¾", "è¯´æœæ²Ÿé€š", "æŠ¥å‘Šæ’°å†™"]
            },
            "é—®é¢˜æ ‘": {
                "name": "æ¡ˆä¾‹å¤ç›˜æ¡†æ¶",
                "structure": "æ ¸å¿ƒé—®é¢˜â†’å­é—®é¢˜æ‹†è§£â†’æ ¹å› åˆ†æâ†’è§£å†³æ–¹æ¡ˆâ†’å®æ–½è·¯å¾„",
                "é€‚ç”¨": ["æ¡ˆä¾‹åˆ†æ", "äº‹åå¤ç›˜", "é—®é¢˜è¯Šæ–­"]
            },
            "å†³ç­–çŸ©é˜µ": {
                "name": "å¯¹æ¯”è¯„ä¼°æ¡†æ¶",
                "structure": "é€‰é¡¹åˆ—ä¸¾â†’è¯„åˆ¤æ ‡å‡†â†’æƒé‡åˆ†é…â†’å¾—åˆ†è¯„ä¼°â†’æœ€ä¼˜é€‰æ‹©",
                "é€‚ç”¨": ["å¤šæ–¹æ¡ˆå¯¹æ¯”", "é€‰æ‹©å†³ç­–", "è¯„ä¼°æ’åº"]
            },
            "æƒ…æ™¯åˆ†æ": {
                "name": "æœªæ¥é¢„æµ‹æ¡†æ¶",
                "structure": "å½“å‰çŠ¶æ€â†’é©±åŠ¨å› ç´ â†’å¯èƒ½æƒ…æ™¯â†’æ¦‚ç‡è¯„ä¼°â†’åº”å¯¹ç­–ç•¥",
                "é€‚ç”¨": ["æœªæ¥å±•æœ›", "é£é™©é¢„åˆ¤", "æˆ˜ç•¥è§„åˆ’"]
            }
        }

    def _calculate_viral_potential(self, news_item):
        """
        ğŸ”¥ Step 2: è®¡ç®—çˆ†ç«æ½œåŠ›è¯„åˆ†
        è¯„åˆ†ç»´åº¦ï¼šæ–°é²œåº¦(30%) + äº‰è®®æ€§(25%) + å—ä¼—è¦†ç›–(20%) + ä¼ æ’­é€Ÿåº¦(15%) + æƒ…ç»ªå¼ºåº¦(10%)
        """
        score = 0
        # ğŸ”¥ FIX: å…¼å®¹ Tavily API çš„ä¸åŒå­—æ®µå (title/name, content/snippet)
        title = news_item.get('title') or news_item.get('name') or ''
        content_text = news_item.get('content') or news_item.get('snippet') or news_item.get('description') or ''
        content = (title + ' ' + content_text).lower()
        
        # 1. æ–°é²œåº¦ (30åˆ†) - åŸºäºå‘å¸ƒæ—¶é—´
        published_at = news_item.get('published_date', '')
        if published_at:
            # ç®€å•å¤„ç†ï¼šå¦‚æœæœ‰ä»Šå¤©çš„å…³é”®è¯ï¼Œå¾—é«˜åˆ†
            if 'today' in published_at or datetime.datetime.now().strftime('%Y-%m-%d') in published_at:
                score += 30
            else:
                score += 15
        else:
            score += 20  # é»˜è®¤åˆ†
        
        # 2. äº‰è®®æ€§ (25åˆ†) - å…³é”®è¯æ£€æµ‹
        controversial_words = ['äº‰è®®', 'controversial', 'å´©ç›˜', 'crash', 'æš´æ¶¨', 'surge', 
                              'è¯ˆéª—', 'scam', 'èµ·è¯‰', 'lawsuit', 'ç›‘ç®¡', 'regulation']
        controversy_score = sum(5 for word in controversial_words if word in content)
        score += min(25, controversy_score)
        
        # 3. å—ä¼—è¦†ç›–é¢ (20åˆ†) - è¯é¢˜çƒ­åº¦
        hot_topics = ['bitcoin', 'btc', 'ethereum', 'eth', 'ai', 'solana', 'sec', 'binance']
        coverage_score = sum(5 for topic in hot_topics if topic in content)
        score += min(20, coverage_score)
        
        # 4. ä¼ æ’­é€Ÿåº¦ (15åˆ†) - æ¥æºæƒå¨æ€§
        trusted_sources = ['coindesk', 'cointelegraph', 'theblock', 'decrypt']
        source = news_item.get('url', '').lower()
        if any(s in source for s in trusted_sources):
            score += 15
        else:
            score += 8
        
        # 5. æƒ…ç»ªå¼ºåº¦ (10åˆ†) - å¼ºæƒ…æ„Ÿè¯
        emotion_words = ['æƒŠäºº', 'shocking', 'å²æ— å‰ä¾‹', 'unprecedented', 'é‡å¤§', 'major']
        emotion_score = sum(3 for word in emotion_words if word in content)
        score += min(10, emotion_score)
        
        return score

    def _match_framework(self, news_item):
        """
        ğŸ”¥ Step 3-4: æ™ºèƒ½æ¡†æ¶åŒ¹é…
        æ ¹æ®æ–°é—»ç±»å‹è‡ªåŠ¨é€‰æ‹©æœ€ä½³åˆ†ææ¡†æ¶
        """
        # ğŸ”¥ FIX: å…¼å®¹ä¸åŒå­—æ®µå
        title = news_item.get('title') or news_item.get('name') or ''
        content_text = news_item.get('content') or news_item.get('snippet') or news_item.get('description') or ''
        content = (title + ' ' + content_text).lower()
        
        # å…³é”®è¯ â†’ æ¡†æ¶æ˜ å°„
        framework_keywords = {
            "5W1H": ["çªå‘", "breaking", "åˆšåˆš", "just", "æœ€æ–°", "latest"],
            "PEST": ["è¶‹åŠ¿", "trend", "å±•æœ›", "outlook", "æœªæ¥", "future"],
            "MECE": ["åˆ†æ", "analysis", "æ·±åº¦", "deep dive", "è¯¦è§£"],
            "SWOT": ["äººç‰©", "ceo", "åˆ›å§‹äºº", "founder", "é¡¹ç›®", "project"],
            "åˆ©ç›Šç›¸å…³è€…": ["æ”¿ç­–", "policy", "ç›‘ç®¡", "regulation", "æ³•æ¡ˆ", "law"],
            "æ³¢ç‰¹äº”åŠ›": ["ç«äº‰", "competition", "å¸‚åœº", "market", "è¡Œä¸š", "industry"],
            "é‡‘å­—å¡”åŸç†": ["è§‚ç‚¹", "opinion", "è¯„è®º", "commentary"],
            "é—®é¢˜æ ‘": ["å¤±è´¥", "failure", "å´©ç›˜", "crash", "å¤ç›˜", "post-mortem"],
            "å†³ç­–çŸ©é˜µ": ["å¯¹æ¯”", "comparison", "é€‰æ‹©", "choice", "vs"],
            "æƒ…æ™¯åˆ†æ": ["é¢„æµ‹", "prediction", "å±•æœ›", "forecast", "å¯èƒ½", "potential"]
        }
        
        # ç»Ÿè®¡æ¯ä¸ªæ¡†æ¶çš„åŒ¹é…åº¦
        match_scores = {}
        for framework, keywords in framework_keywords.items():
            match_scores[framework] = sum(1 for kw in keywords if kw in content)
        
        # é€‰æ‹©åŒ¹é…åº¦æœ€é«˜çš„æ¡†æ¶
        best_framework = max(match_scores.items(), key=lambda x: x[1])[0]
        
        # å¦‚æœæ‰€æœ‰æ¡†æ¶å¾—åˆ†éƒ½æ˜¯0ï¼Œé»˜è®¤ä½¿ç”¨5W1H
        if match_scores[best_framework] == 0:
            best_framework = "5W1H"
        
        return best_framework

    def _collect_evidence(self, topic, news_item):
        """
        ğŸ”¥ Step 5: è¯æ®æ”¶é›†ä¸ä¸¥æ ¼ç­›é€‰
        å¹¿æ³›æ”¶é›†æ­£åé¢è¯æ® â†’ æ—¶æ•ˆæ€§æ£€æŸ¥ â†’ é€»è¾‘æ€§éªŒè¯ â†’ å¯é æ€§è¯„ä¼°
        """
        print("ğŸ“š Step 5: æ”¶é›†å’Œç­›é€‰è¯æ®...")
        
        # ğŸ”¥ FIX: å…¼å®¹ä¸åŒå­—æ®µå
        title = news_item.get('title') or news_item.get('name') or ''
        
        # 1. å¹¿æ³›æ”¶é›†ï¼ˆæ­£åé¢ï¼‰
        try:
            search_query = f"{topic} {title}"
            evidence_pool = self.tavily.search(
                query=search_query,
                search_depth="advanced",
                max_results=10,
                days=3  # æ‰©å¤§åˆ°3å¤©ï¼Œç¡®ä¿è¶³å¤Ÿè¯æ®
            )
            raw_evidence = evidence_pool.get("results", [])
        except Exception as e:
            print(f"âš ï¸ è¯æ®æ”¶é›†å¤±è´¥: {e}")
            raw_evidence = [news_item]  # å¤±è´¥æ—¶è‡³å°‘ç”¨åŸæ–°é—»
        
        # 2. æ—¶æ•ˆæ€§æ£€æŸ¥ï¼ˆåˆ é™¤è¿‡æ—¶ä¿¡æ¯ï¼‰
        valid_evidence = []
        for e in raw_evidence:
            # ç®€å•æ£€æŸ¥ï¼šæœ‰å‘å¸ƒæ—¥æœŸä¸”ä¸æ˜¯å¤ªæ—§
            pub_date = e.get('published_date', '')
            if pub_date or 'http' in e.get('url', ''):
                valid_evidence.append(e)
        
        # 3. é€»è¾‘æ€§éªŒè¯ï¼ˆç²—ç­›ï¼‰
        # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…åº”è¯¥æ£€æŸ¥å†…å®¹ç›¸å…³æ€§
        logical_evidence = valid_evidence[:8]  # å–å‰8ä¸ªæœ€ç›¸å…³çš„
        
        # 4. å¯é æ€§è¯„ä¼°ï¼ˆæ£€æŸ¥æ¥æºï¼‰
        reliable_evidence = []
        for e in logical_evidence:
            url = e.get('url', '').lower()
            # ä¼˜å…ˆæ¥è‡ªå¯ä¿¡æº
            is_trusted = any(source in url for source in ['coindesk', 'cointelegraph', 'theblock', 'decrypt', 'reuters', 'bloomberg'])
            if is_trusted or len(reliable_evidence) < 3:  # ç¡®ä¿è‡³å°‘3æ¡
                reliable_evidence.append(e)
        
        print(f"âœ… è¯æ®ç­›é€‰å®Œæˆ: åŸå§‹{len(raw_evidence)}æ¡ â†’ æœ‰æ•ˆ{len(valid_evidence)}æ¡ â†’ å¯é {len(reliable_evidence)}æ¡")
        return reliable_evidence

    def _organize_content(self, evidence, framework, news_item):
        """
        ğŸ”¥ Step 6: å†…å®¹ç»„ç»‡ï¼ˆé‡‘å­—å¡”åŸç†ï¼‰
        æŒ‰æ¡†æ¶ç»“æ„ç»„ç»‡ç´ æï¼Œè°ƒèŠ‚èŠ‚å¥ï¼Œæ§åˆ¶ç¯‡å¹…
        """
        print(f"ğŸ“ Step 6: æŒ‰ {framework} æ¡†æ¶ç»„ç»‡å†…å®¹...")
        
        framework_info = self.frameworks.get(framework, self.frameworks["5W1H"])
        
        # ğŸ”¥ FIX: å…¼å®¹ä¸åŒå­—æ®µå
        title = news_item.get('title') or news_item.get('name') or ''
        content_text = news_item.get('content') or news_item.get('snippet') or news_item.get('description') or ''
        url = news_item.get('url') or ''
        
        # æ„å»ºç»“æ„åŒ–çš„ç´ æåŒ…
        organized = {
            "æ¡†æ¶åç§°": framework_info["name"],
            "ç»“æ„": framework_info["structure"],
            "ä¸»æ–°é—»": {
                "æ ‡é¢˜": title,
                "å†…å®¹": content_text,
                "æ¥æº": url
            },
            "æ”¯æ’‘è¯æ®": [
                {
                    "æ ‡é¢˜": e.get('title') or e.get('name') or '',
                    "æ‘˜è¦": (e.get('content') or e.get('snippet') or e.get('description') or '')[:200],
                    "æ¥æº": e.get('url') or ''
                }
                for e in evidence[:3]  # æœ€å¤š3æ¡æ”¯æ’‘
            ]
        }
        
        return organized

    def _check_duplication(self, new_topic):
        """
        å»é‡æœºåˆ¶ï¼šé¿å…çŸ­æ—¶é—´å†…é‡å¤è®²åŒä¸€ä¸ªæ–°é—»
        """
        # ğŸ”¥ FIX: å¤„ç†ç©ºæ ‡é¢˜æƒ…å†µ
        if not new_topic or new_topic.strip() == '':
            print("âš ï¸ æ ‡é¢˜ä¸ºç©ºï¼Œè·³è¿‡å»é‡æ£€æŸ¥")
            return False
        try:
            if not os.path.exists(HISTORY_FILE):
                with open(HISTORY_FILE, "w") as f:
                    json.dump([{"topic": new_topic, "time": time.time()}], f)
                return False
            
            with open(HISTORY_FILE, "r") as f: 
                history = json.load(f)
            
            # æ¸…ç†è¶…è¿‡5å°æ—¶çš„æ—§è®°å½•
            current_time = time.time()
            valid_history = [h for h in history if current_time - h['time'] < 5 * 3600]
            
            # æŸ¥é‡ï¼ˆå…³é”®è¯åŒ¹é… + ç›¸ä¼¼åº¦ï¼‰
            is_dup = False
            for h in valid_history:
                if h['topic'] in new_topic or new_topic in h['topic']:
                    is_dup = True
                    break
                # è¯æ±‡ç›¸ä¼¼åº¦æ£€æµ‹
                old_words = set(re.findall(r'\w+', h['topic'].lower()))
                new_words = set(re.findall(r'\w+', new_topic.lower()))
                if len(old_words & new_words) / max(len(new_words), 1) > 0.5:
                    is_dup = True
                    break
            
            # å¦‚æœä¸é‡å¤ï¼Œæ›´æ–°æ–‡ä»¶
            if not is_dup:
                valid_history.append({"topic": new_topic, "time": current_time})
                with open(HISTORY_FILE, "w") as f: 
                    json.dump(valid_history, f, ensure_ascii=False, indent=2)
                print(f"âœ… æ–°è¯é¢˜å·²è®°å½•: {new_topic[:50]}...")
            else:
                print(f"âš ï¸ è¯é¢˜é‡å¤ï¼Œè·³è¿‡: {new_topic[:50]}...")
            
            return is_dup
        except Exception as e:
            print(f"âš ï¸ å»é‡æ£€æŸ¥å¤±è´¥: {e}")
            return False

    def _clean_text(self, text):
        """
        ğŸ”¥ å¼ºåŠ›å»åºŸè¯æ­£åˆ™æ¸…æ´—å™¨ï¼ˆæ‰©å±•ç‰ˆï¼‰
        """
        if not text:
            return ""
        
        # 1. å»æ‰å‰§æœ¬æ ‡è®°
        text = re.sub(r"[\(\[\ã€<].*?[\)\]\ã€‘>]", "", text)
        
        # 2. å»æ‰ Markdown æ ¼å¼
        text = text.replace("*", "").replace("#", "").replace("`", "")
        text = text.replace("_", "").replace("~", "")
        
        # 3. å»æ‰ AI ä¹ æƒ¯æ€§åºŸè¯ï¼ˆæ‰©å±•åˆ—è¡¨ï¼‰
        bad_phrases = [
            "å¥½çš„å¤§æ¼‚äº®", "æ²¡é—®é¢˜", "å¥½çš„", "ç»¼ä¸Šæ‰€è¿°", "æ€»ä¹‹", "æ€»è€Œè¨€ä¹‹",
            "ä¸»æŒäºº", "Let's go", "å„ä½å¬ä¼—", "å¤§å®¶å¥½", "è§‚ä¼—æœ‹å‹ä»¬",
            "æ¥ä¸‹æ¥", "é‚£ä¹ˆ", "é¦–å…ˆ", "å…¶æ¬¡", "æœ€å", "ç„¶å",
            "å€¼å¾—æ³¨æ„çš„æ˜¯", "éœ€è¦æŒ‡å‡ºçš„æ˜¯", "æˆ‘ä»¬å¯ä»¥çœ‹åˆ°", "å¯ä»¥å‘ç°",
            "æ ¹æ®ä»¥ä¸Šåˆ†æ", "é€šè¿‡åˆ†æ", "ç»¼åˆæ¥çœ‹",
            "éŸ³æ•ˆ", "èƒŒæ™¯éŸ³ä¹", "æŒå£°", "ç¬‘å£°",
            "æˆ‘é€‰æ‹©", "æˆ‘è®¤ä¸º", "æˆ‘è§‰å¾—", "è®©æˆ‘ä»¬",
            "æ¬¢è¿æ”¶å¬", "æ„Ÿè°¢æ”¶çœ‹", "ä¸‹æœŸå†è§"
        ]
        for phrase in bad_phrases:
            text = text.replace(phrase, "")
        
        # 4. å»é™¤ä¸é€‚åˆæœ—è¯»çš„æ ‡ç‚¹ç¬¦å·
        text = re.sub(r'["""''ã€Œã€ã€ã€ï¼ˆï¼‰\(\)\[\]ã€ã€‘ã€Šã€‹<>]', '', text)
        
        # 5. è§„èŒƒåŒ–æ ‡ç‚¹
        text = re.sub(r'[ï¼Œ,]{2,}', 'ï¼Œ', text)
        text = re.sub(r'[ã€‚.]{2,}', 'ã€‚', text)
        text = re.sub(r'[ï¼!]{2,}', 'ï¼', text)
        text = re.sub(r'[ï¼Ÿ?]{2,}', 'ï¼Ÿ', text)
        
        # 6. å»é™¤å¤šä½™ç©ºè¡Œ
        lines = [line.strip() for line in text.split("\n") if line.strip()]
        text = "\n".join(lines)
        
        # 7. å»é™¤è¡Œé¦–åºå·
        text = re.sub(r'^\s*[\dä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+[ã€\.\s]+', '', text, flags=re.MULTILINE)
        
        return text.strip()

    def _quality_check(self, draft):
        """
        ğŸ”¥ Step 7: è´¨é‡å®¡æ ¸ï¼ˆå››é‡æ£€æŸ¥ï¼‰
        æ£€æŸ¥è¯­ä¹‰é‡å¤ã€é€»è¾‘æ¼æ´ã€äº‹å®å‡†ç¡®ã€æ—¶é—´æ­£ç¡®
        """
        print("ğŸ” Step 7: è´¨é‡å®¡æ ¸...")
        
        issues = []
        char_count = len(draft)
        
        # 1. è¯­ä¹‰é‡å¤æ£€æŸ¥ï¼ˆç®€å•ç‰ˆï¼‰
        sentences = re.split(r'[ã€‚ï¼ï¼Ÿ]', draft)
        unique_sentences = set(sentences)
        if len(sentences) - len(unique_sentences) > 3:
            issues.append("æ£€æµ‹åˆ°è¾ƒå¤šé‡å¤å¥å­")
        
        # 2. å­—æ•°æ£€æŸ¥ï¼ˆæ›´ä¸¥æ ¼çš„æ ‡å‡†ï¼‰
        print(f"ğŸ“Š å½“å‰å­—æ•°: {char_count} å­—")
        if char_count < 800:
            issues.append(f"å†…å®¹è¿‡çŸ­ï¼ˆ{char_count}å­—ï¼‰ï¼Œç›®æ ‡è‡³å°‘1500å­—")
        elif char_count >= 800 and char_count < 1200:
            print(f"âš ï¸ å­—æ•°åå°‘ï¼ˆ{char_count}å­—ï¼‰ï¼Œç†æƒ³å€¼1500-2500å­—")
        elif char_count > 3500:
            issues.append(f"å†…å®¹è¿‡é•¿ï¼ˆ{char_count}å­—ï¼‰ï¼Œå»ºè®®æ§åˆ¶åœ¨2500å­—ä»¥å†…")
        else:
            print(f"âœ… å­—æ•°åˆæ ¼ï¼ˆ{char_count}å­—ï¼‰")
        
        # 3. æ£€æŸ¥æ˜¯å¦æœ‰å®è´¨å†…å®¹
        if "åˆ†æ" not in draft and "å½±å“" not in draft and "åŸå› " not in draft:
            issues.append("ç¼ºå°‘æ·±åº¦åˆ†æ")
        
        if issues:
            print(f"âš ï¸ å‘ç°é—®é¢˜: {', '.join(issues)}")
            return False, issues
        else:
            print("âœ… è´¨é‡å®¡æ ¸é€šè¿‡")
            return True, []

    def fetch_news_and_analyze(self):
        """
        ğŸ”¥ 10æ­¥ä¸“ä¸šå·¥ä½œæµç¨‹ï¼ˆä¸»æµç¨‹ï¼‰
        """
        if not self.tavily: 
            return None, "ç¼ºå°‘ Tavily Key", False
        
        print("\n" + "="*50)
        print("ğŸ™ï¸ åŠ å¯†å¤§æ¼‚äº® - 10æ­¥ä¸“ä¸šå†…å®¹ç”Ÿäº§æµç¨‹")
        print("="*50)
        
        # Step 1-2: å®æ—¶çƒ­ç‚¹è¿½è¸ªä¸ç­›é€‰
        today_str = datetime.datetime.now().strftime("%Y-%m-%d")
        print(f"\nğŸ“¡ Step 1-2: è¿½è¸ªçƒ­ç‚¹å¹¶ç­›é€‰çˆ†ç«è¯é¢˜ ({today_str})")
        
        domain_list = [d.strip() for d in self.target_domains.split(",") if d.strip()]
        
        try:
            response = self.tavily.search(
                query=f"crypto blockchain {self.topic} breaking news {today_str}",
                search_depth="advanced",
                include_domains=domain_list if domain_list else None,
                max_results=15,  # å¢åŠ åˆ°15æ¡ï¼Œæ–¹ä¾¿ç­›é€‰
                days=1
            )
            results = response.get("results", [])
            print(f"âœ… æœç´¢åˆ° {len(results)} æ¡å€™é€‰æ–°é—»")
        except Exception as e:
            print(f"âŒ æœç´¢å¤±è´¥: {e}")
            return None, f"æœç´¢å¤±è´¥: {e}", False

        # è®¡ç®—çˆ†ç«æ½œåŠ›å¹¶æ’åº
        scored_results = []
        for item in results:
            score = self._calculate_viral_potential(item)
            scored_results.append((score, item))
        
        scored_results.sort(reverse=True, key=lambda x: x[0])
        print(f"ğŸ“Š çˆ†ç«æ½œåŠ›æ’åºå®Œæˆï¼ŒTop1å¾—åˆ†: {scored_results[0][0] if scored_results else 0}")
        
        # ç­›é€‰æœªè®²è¿‡çš„æ–°é—»
        selected_news = None
        selected_framework = None
        
        for score, item in scored_results:
            # ğŸ”¥ FIX: å…¼å®¹ä¸åŒå­—æ®µå
            title = item.get('title') or item.get('name') or ''
            if not title:
                print("âš ï¸ å‘ç°æ— æ ‡é¢˜æ–°é—»ï¼Œè·³è¿‡")
                continue
                
            if not self._check_duplication(title):
                selected_news = item
                # Step 3-4: æ™ºèƒ½æ¡†æ¶åŒ¹é…
                selected_framework = self._match_framework(item)
                print(f"âœ… é€‰ä¸­å¤´æ¡: {title[:50]}...")
                print(f"ğŸ¯ Step 3-4: åŒ¹é…æ¡†æ¶ â†’ {selected_framework} ({self.frameworks[selected_framework]['name']})")
                break
        
        # æ²¡æ–°é—» â†’ å¯ç”¨ CMS å¤‡ç”¨åº“
        if not selected_news:
            print("âš ï¸ æ— æœ€æ–°é«˜ä»·å€¼æ–°é—»æˆ–éƒ½å·²è®²è¿‡ï¼Œå¯ç”¨å¤‡ç”¨è¯é¢˜åº“...")
            import random
            backup = random.choice(self.backup_topics) if self.backup_topics else "æ¯”ç‰¹å¸å»ä¸­å¿ƒåŒ–ç²¾ç¥ç§‘æ™®"
            print(f"ğŸ“š ä½¿ç”¨å¤‡ç”¨è¯é¢˜: {backup}")
            return backup, None, True

        # Step 5: è¯æ®æ”¶é›†ä¸ç­›é€‰
        evidence = self._collect_evidence(self.topic, selected_news)
        
        # Step 6: å†…å®¹ç»„ç»‡
        organized_content = self._organize_content(evidence, selected_framework, selected_news)
        
        # Step 8-10: AI ç”Ÿæˆæ–‡æ¡ˆ
        print("\nğŸ§  Step 8-10: AIæ·±åº¦æ’°å†™ä¸ä¼˜åŒ–...")
        
        framework_info = self.frameworks[selected_framework]
        
        # ğŸ”¥ FIX: å…¼å®¹ä¸åŒå­—æ®µå
        title = selected_news.get('title') or selected_news.get('name') or ''
        content_text = selected_news.get('content') or selected_news.get('snippet') or selected_news.get('description') or ''
        url = selected_news.get('url') or ''
        
        # ğŸ”¥ æ ¸å¿ƒ Prompt - 10æ­¥ä¸“ä¸šæµç¨‹ç‰ˆ
        prompt = f"""
{self.persona}

ã€åˆ†æä»»åŠ¡ã€‘
ä½ æ­£åœ¨ä½¿ç”¨ **{framework_info['name']}** è¿›è¡Œæ·±åº¦åˆ†æã€‚

æ¡†æ¶ç»“æ„: {framework_info['structure']}

ã€åŸå§‹æ–°é—»ã€‘
æ ‡é¢˜ï¼š{title}
å†…å®¹ï¼š{content_text}
æ¥æºï¼š{url}

ã€æ”¯æ’‘è¯æ®ã€‘
{chr(10).join([f"- {e['æ ‡é¢˜']}" for e in organized_content['æ”¯æ’‘è¯æ®']])}

ã€åˆ›ä½œè¦æ±‚ - ä¸¥æ ¼æ‰§è¡Œã€‘

1. **æ¡†æ¶åº”ç”¨**ï¼š
   - ä¸¥æ ¼æŒ‰ç…§ {selected_framework} æ¡†æ¶çš„ç»“æ„å±•å¼€
   - æ¯ä¸ªç¯èŠ‚éƒ½è¦æœ‰å®è´¨æ€§åˆ†æï¼Œä¸æ˜¯ç®€å•ç½—åˆ—
   - é€»è¾‘é“¾æ¡è¦å®Œæ•´ï¼Œç¯ç¯ç›¸æ‰£

2. **æ·±åº¦æŒ–æ˜**ï¼š
   - ä¸èƒ½åªå¤è¿°æ–°é—»ï¼Œå¿…é¡»æœ‰ç‹¬åˆ°è§è§£
   - æŒ–æ˜èƒŒåçš„æ·±å±‚åŸå› å’Œå½±å“
   - æå‡ºæœ‰ä»·å€¼çš„é¢„æµ‹æˆ–å»ºè®®
   - æ¯ä¸ªåˆ†æç‚¹è‡³å°‘å±•å¼€3-5å¥è¯ï¼Œä¸è¦ä¸€ç¬”å¸¦è¿‡
   - ç”¨å…·ä½“æ¡ˆä¾‹å’Œæ•°æ®æ”¯æ’‘ä½ çš„è§‚ç‚¹

3. **å£è¯­åŒ–è¡¨è¾¾**ï¼š
   - å¥å­è¦çŸ­ï¼Œå¹³å‡15å­—ä»¥å†…
   - åƒå’Œæœ‹å‹èŠå¤©ä¸€æ ·è‡ªç„¶
   - é€‚åˆå¥³æ€§ä¸»æŒäººçš„è¯­æ°”
   - å¸¦ç‚¹å¹½é»˜å’Œä¸ªæ€§

4. **å†…å®¹æ§åˆ¶**ï¼š
   - å­—æ•°ï¼š1500-2500å­—ï¼ˆç›®æ ‡8-15åˆ†é’Ÿæ’­æŠ¥æ—¶é•¿ï¼‰
   - èŠ‚å¥ï¼šæœ‰å¿«æœ‰æ…¢ï¼Œæœ‰é‡ç‚¹æœ‰å±•å¼€
   - ç»“æ„ï¼šæ¸…æ™°çš„å¼€å¤´ã€ä¸­é—´ã€ç»“å°¾
   - æ·±åº¦ï¼šå……åˆ†å±•å¼€æ¯ä¸ªåˆ†æç‚¹ï¼Œä¸è¦ç®€ç•¥æ¦‚æ‹¬

5. **ä¸¥ç¦äº‹é¡¹**ï¼š
   - ä¸è¦è¾“å‡º"æˆ‘é€‰æ‹©äº†XXæ¡†æ¶"ç­‰å…ƒè¯­è¨€
   - ä¸è¦ç”¨"å¥½çš„""æ²¡é—®é¢˜""ç»¼ä¸Šæ‰€è¿°"
   - ä¸è¦å‡ºç°(éŸ³æ•ˆ)ã€[åŠ¨ä½œ]ç­‰å‰§æœ¬æ ‡è®°
   - ä¸è¦ç”¨å¼•å·ã€æ‹¬å·ç­‰ä¸é€‚åˆæœ—è¯»çš„ç¬¦å·
   - åªç”¨é€—å·ã€å¥å·ã€é—®å·ã€æ„Ÿå¹å·

6. **è¯­æ°”é£æ ¼**ï¼š
   - ä¸“ä¸šä½†ä¸æ­»æ¿
   - çŠ€åˆ©ä½†ä¸åæ¿€
   - çŸ¥æ€§ä½†ä¸é«˜å†·
   - æœ‰è§‚ç‚¹æœ‰æ€åº¦

âš ï¸ **é‡è¦æé†’**ï¼š
- ç›®æ ‡å­—æ•°ï¼š1500-2500å­—ï¼ˆçº¦8-15åˆ†é’Ÿæ’­æŠ¥æ—¶é•¿ï¼‰
- å¦‚æœå­—æ•°ä¸è¶³1500å­—ï¼Œå°†è¢«é€€å›é‡å†™
- å……åˆ†å±•å¼€åˆ†æï¼Œä¸è¦ç®€ç•¥æ¦‚æ‹¬
- æ¯ä¸ªè®ºç‚¹éƒ½è¦æœ‰è¶³å¤Ÿçš„è®ºè¯æ”¯æ’‘

ğŸ”´ **ä¸¥æ ¼å­—æ•°è¦æ±‚ - å¿…é¡»éµå®ˆï¼**ï¼š
- æœ€å°‘1500å­—ï¼Œç†æƒ³2000å­—ä»¥ä¸Š
- æ¯ä¸ªæ¡†æ¶ç¯èŠ‚è‡³å°‘200-300å­—
- ä¸è¦å†™æˆç®€çŸ­çš„æ–°é—»ç¨¿ï¼Œè¦å†™æˆæ·±åº¦åˆ†æé•¿æ–‡
- å‚è€ƒç¤ºä¾‹ï¼šä¸€ä¸ªå®Œæ•´çš„åˆ†æåº”è¯¥åƒä¸€ç¯‡æ·±åº¦æŠ¥é“æ–‡ç« 

ğŸ’¡ **å¦‚ä½•è¾¾åˆ°å­—æ•°è¦æ±‚**ï¼š
1. æ¯ä¸ªè®ºç‚¹éƒ½è¦æœ‰ï¼šè§‚ç‚¹é™ˆè¿° + äº‹å®æ”¯æ’‘ + æ•°æ®å¼•ç”¨ + å½±å“åˆ†æ
2. å¤šç”¨å…·ä½“ä¾‹å­ï¼šä¸è¦è¯´"ä¼šæœ‰å½±å“"ï¼Œè¦è¯´"å…·ä½“ä¼šå¯¹XXå¸‚åœºé€ æˆXXå½±å“ï¼Œé¢„è®¡XX"
3. å±•å¼€æ—¶é—´çº¿ï¼šä¸è¦åªè¯´"å‘ç”Ÿäº†"ï¼Œè¦è¯´"ä½•æ—¶å¼€å§‹ã€å¦‚ä½•å‘å±•ã€ç°åœ¨çŠ¶å†µã€æœªæ¥èµ°å‘"
4. å¤šè§’åº¦åˆ†æï¼šä»æŠ•èµ„è€…ã€ç›‘ç®¡è€…ã€è¡Œä¸šå‚ä¸è€…ç­‰å¤šä¸ªè§†è§’åˆ†æ

ç°åœ¨å¼€å§‹åˆ›ä½œï¼Œç›´æ¥è¾“å‡ºæ–‡æ¡ˆæ­£æ–‡ï¼ˆè®°ä½ï¼šè‡³å°‘1500å­—ï¼ï¼‰ï¼š
"""
        
        try:
            # ğŸ”¥ å¤šæ¬¡å°è¯•æœºåˆ¶ï¼šç¡®ä¿ç”Ÿæˆé«˜è´¨é‡é•¿å†…å®¹
            max_attempts = 3
            best_script = None
            best_char_count = 0
            
            for attempt in range(max_attempts):
                print(f"ğŸ¨ ç¬¬ {attempt + 1} æ¬¡ç”Ÿæˆ..." if attempt > 0 else "ğŸ¨ å¼€å§‹ç”Ÿæˆå†…å®¹...")
                
                # æ ¹æ®å°è¯•æ¬¡æ•°è°ƒæ•´ prompt
                if attempt == 0:
                    current_prompt = prompt
                elif attempt == 1:
                    # ç¬¬äºŒæ¬¡ï¼šå¼ºè°ƒå­—æ•°è¦æ±‚
                    current_prompt = prompt.replace(
                        "ç°åœ¨å¼€å§‹åˆ›ä½œï¼Œç›´æ¥è¾“å‡ºæ–‡æ¡ˆæ­£æ–‡ï¼ˆè®°ä½ï¼šè‡³å°‘1500å­—ï¼ï¼‰ï¼š",
                        "ğŸš¨ğŸš¨ğŸš¨ ä¸Šä¸€æ¬¡ç”Ÿæˆå¤±è´¥ï¼šå­—æ•°ä¸¥é‡ä¸è¶³ï¼ğŸš¨ğŸš¨ğŸš¨\n\n" +
                        "ç¬¬äºŒæ¬¡å°è¯• - å¿…é¡»æ»¡è¶³ä»¥ä¸‹è¦æ±‚ï¼š\n" +
                        "1. æœ€å°‘1500å­—ï¼Œç›®æ ‡2000å­—ä»¥ä¸Š\n" +
                        "2. æ¯ä¸ªæ¡†æ¶ç¯èŠ‚è¯¦ç»†å±•å¼€ï¼Œè‡³å°‘5-8å¥è¯\n" +
                        "3. ä¸è¦å†™ç®€çŸ­æ¦‚æ‹¬ï¼Œè¦å†™æ·±åº¦é•¿æ–‡\n" +
                        "4. å¤šç”¨å…·ä½“æ•°æ®ã€æ¡ˆä¾‹ã€æ—¶é—´çº¿\n\n" +
                        "ç°åœ¨å¼€å§‹åˆ›ä½œï¼Œè¾“å‡ºè‡³å°‘1500å­—çš„å®Œæ•´åˆ†æï¼š"
                    )
                else:
                    # ç¬¬ä¸‰æ¬¡ï¼šæœ€ä¸¥å‰è­¦å‘Š
                    current_prompt = prompt.replace(
                        "ç°åœ¨å¼€å§‹åˆ›ä½œï¼Œç›´æ¥è¾“å‡ºæ–‡æ¡ˆæ­£æ–‡ï¼ˆè®°ä½ï¼šè‡³å°‘1500å­—ï¼ï¼‰ï¼š",
                        "ğŸ”¥ğŸ”¥ğŸ”¥ æœ€åæœºä¼šï¼å‰ä¸¤æ¬¡éƒ½å¤±è´¥äº†ï¼ğŸ”¥ğŸ”¥ğŸ”¥\n\n" +
                        "ç¬¬ä¸‰æ¬¡å°è¯• - ç»ˆæè¦æ±‚ï¼š\n" +
                        "ğŸ“ å¿…é¡»ç”Ÿæˆè‡³å°‘1500å­—çš„æ·±åº¦åˆ†ææ–‡ç« \n" +
                        "ğŸ“ æ¯ä¸ªè®ºç‚¹å±•å¼€è‡³å°‘300å­—\n" +
                        "ğŸ“ åƒå†™è®ºæ–‡ä¸€æ ·è¯¦ç»†ã€åƒæŠ¥é“ä¸€æ ·æ·±å…¥\n" +
                        "ğŸ“ ä¸è¦ç®€ç•¥ã€ä¸è¦æ¦‚æ‹¬ã€ä¸è¦çœç•¥\n\n" +
                        "ç¤ºä¾‹é•¿åº¦å‚è€ƒï¼š\n" +
                        "- å¼€å¤´å¼•å…¥ï¼š200-300å­—\n" +
                        "- æ¯ä¸ªæ¡†æ¶ç¯èŠ‚ï¼š300-400å­— Ã— 4-5ä¸ªç¯èŠ‚ = 1200-2000å­—\n" +
                        "- ç»“å°¾æ€»ç»“ï¼š200-300å­—\n" +
                        "æ€»è®¡ï¼š1500-2500å­—\n\n" +
                        "ç«‹å³å¼€å§‹åˆ›ä½œå®Œæ•´çš„æ·±åº¦åˆ†æé•¿æ–‡ï¼š"
                    )
                
                raw_script = self.llm.invoke(current_prompt).content
                print(f"ğŸ“ åŸå§‹ç”Ÿæˆå­—æ•°: {len(raw_script)} å­—")
                
                clean_script = self._clean_text(raw_script)
                print(f"ğŸ§¹ æ¸…æ´—åå­—æ•°: {len(clean_script)} å­—")
                
                # ğŸ”¥ å¦‚æœæ¸…æ´—åæŸå¤±è¶…è¿‡30%ï¼Œä½¿ç”¨åŸå§‹ç‰ˆæœ¬
                if len(clean_script) < len(raw_script) * 0.7:
                    print(f"âš ï¸ æ¸…æ´—æŸå¤±è¿‡å¤šï¼ˆ{100 - len(clean_script)/len(raw_script)*100:.1f}%ï¼‰ï¼Œä½¿ç”¨åŸå§‹æ–‡æœ¬")
                    clean_script = raw_script
                
                # è®°å½•æœ€ä½³ç»“æœ
                if len(clean_script) > best_char_count:
                    best_script = clean_script
                    best_char_count = len(clean_script)
                
                # Step 7: è´¨é‡å®¡æ ¸
                passed, issues = self._quality_check(clean_script)
                
                if passed:
                    print(f"âœ… æ–‡æ¡ˆç”Ÿæˆå®Œæˆï¼Œå…± {len(clean_script)} å­—")
                    print("="*50 + "\n")
                    return clean_script, None, False
                else:
                    print(f"âŒ ç¬¬ {attempt + 1} æ¬¡ç”Ÿæˆæœªé€šè¿‡å®¡æ ¸: {', '.join(issues)}")
                    if attempt < max_attempts - 1:
                        print(f"ğŸ”„ å°†è¿›è¡Œç¬¬ {attempt + 2} æ¬¡å°è¯•...")
            
            # å¦‚æœæ‰€æœ‰å°è¯•éƒ½å¤±è´¥ï¼Œè¿”å›æœ€ä½³ç»“æœ
            print(f"âš ï¸ {max_attempts} æ¬¡å°è¯•åï¼Œä½¿ç”¨æœ€ä½³ç»“æœï¼ˆ{best_char_count}å­—ï¼‰")
            print("="*50 + "\n")
            return best_script if best_script else clean_script, None, False
            
        except Exception as e:
            print(f"âŒ ç”Ÿæˆå¤±è´¥: {e}")
            return None, f"ç”Ÿæˆå¤±è´¥: {e}", False
